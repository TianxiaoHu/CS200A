{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Tianxiao Hu\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f648b5d18203ec0ee3d66e04da934769",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Lab 09: Logistic regression \n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your solution.\n",
    "\n",
    "## Due Date\n",
    "\n",
    "This assignment is due at 11:59pm Monday, October 29nd.\n",
    "\n",
    "In this lab, you will practice logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborators  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write names in this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63d1bf244018d538a65aeefed4239848",
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import cufflinks as cf\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "py.init_notebook_mode(connected=False)\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df26c25b6499739578a222974ec30032",
     "grade": false,
     "grade_id": "dataset",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In this lab, we will be working on the breast cancer dataset. This dataset can be easily loaded using the `sklearn.datasets.load_breast_cancer()` method.  \n",
    "The data format is not a `pandas.DataFrame` so we will create a new DataFrame from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8ed8e0cf695986b820036c66fc171df",
     "grade": false,
     "grade_id": "loaddata",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data = sklearn.datasets.load_breast_cancer()\n",
    "# data is actually a dictionnary\n",
    "print(data.keys())\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e49da25e478353779bbf38379eea46f",
     "grade": false,
     "grade_id": "dataframe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69b22a71e6a1c5466adb90d589293b69",
     "grade": false,
     "grade_id": "fitone",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let us try to fit a simple model with only one feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81b6fe5f8e16368f567e09bf3b6c414d",
     "grade": false,
     "grade_id": "buildxy",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Define our features/target\n",
    "X = df[[\"mean radius\"]]\n",
    "# Target data['target'] = 0 is malignant 1 is benign\n",
    "Y = (data.target == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb4b7906c544aa687dab0a5407abf513",
     "grade": false,
     "grade_id": "split",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Split between train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Training Data Size: {len(x_train)}\")\n",
    "print(f\"Test Data Size: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4c6ac639c34f0daf409cab0c6a3b64d",
     "grade": false,
     "grade_id": "q1_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Now let us first fit a logistic regression model using the training set.  \n",
    "We will compute the training and testing accuracy, defined as:\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\text{Training Accuracy} = \\frac{1}{n_{train\\_set}} \\sum_{i \\in \\text{train_set}} {\\mathbb{1}_{y_i == \\hat{y_i}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large\n",
    "\\text{Testing Accuracy} = \\frac{1}{n_{test\\_set}} \\sum_{i \\in \\text{test_set}} {\\mathbb{1}_{y_i == \\hat{y_i}}}\n",
    "$$\n",
    "\n",
    "where $ y_i $ is the prediction of our model, $ y_i $ the ground truth and $\\mathbb{1}_{y_i == \\hat{y_i}}$ an indicator function ($ \\mathbb{1}_{y_i == \\hat{y_i}} = 1 \\iff  y_i = \\hat{y_i}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de04eb19066477b45ba64434a3eff8ad",
     "grade": false,
     "grade_id": "q1_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "lr = sklearn.linear_model.LogisticRegression(fit_intercept=True)\n",
    "lr.fit(x_train, y_train)\n",
    "train_accuracy = sum(y_train == lr.predict(x_train)) / len(y_train)\n",
    "test_accuracy = sum(y_test == lr.predict(x_test)) / len(y_test)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49838d9acfe464378fddf35c906fdf34",
     "grade": true,
     "grade_id": "q1_test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert sum(lr.predict(x_test) == y_test) == 131"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72da218eff8a4acd45449977b455bc74",
     "grade": false,
     "grade_id": "q2_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "It seems we can a get very high test accuracy. Then how about precision and recall?  \n",
    "- Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances.  \n",
    "- Recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.\n",
    "\n",
    "Precision is the ability of the classifier not to label as positive a sample that is negative while recall is the ability of the classifier to find all the positive samples.\n",
    "\n",
    "To understand the link between recall/precision on the one hand and sensitivity/specificity on the other hand, it's useful to come back to a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34eae718e46af4e50173349eef9d173d",
     "grade": false,
     "grade_id": "q2_display",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, lr.predict(x_test))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "class_names = ['False', 'True']\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac54cd4de1617029c92900a722f69bca",
     "grade": false,
     "grade_id": "q2_text2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Then:\n",
    "$$\n",
    "\\text{Precision} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_positives}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{n_{true\\_positives}}{n_{true\\_positives} + n_{false\\_negatives}}\n",
    "$$\n",
    "\n",
    "As illustrated in the figure below:\n",
    "![precision_recall](precision_recall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f631259d06ed305d6c97b2ac1380c121",
     "grade": false,
     "grade_id": "cell-sd",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now let's compute the precision and recall for the test set using the model we got from question 1.  \n",
    "Please do not use the `sklearn.metrics` for this computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bitwise_and([True, True], [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10f6073ec243060b207990fbc8b44bfc",
     "grade": false,
     "grade_id": "q2_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_test) \n",
    "precision = np.sum(np.bitwise_and(y_pred == 1, y_test == 1)) / np.sum(y_pred == 1)\n",
    "recall = np.sum(np.bitwise_and(y_pred == 1, y_test == 1)) / np.sum(y_test == 1)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "print(f'precision = {precision:.4f}')\n",
    "print(f'recall = {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02a261db65e86043b6e81f2e5c09d253",
     "grade": true,
     "grade_id": "q2_test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(precision, 0.97727272727272729)\n",
    "assert np.isclose(recall, 0.79629629629629628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9a55a8f2904890b71c44437a5fff52d",
     "grade": false,
     "grade_id": "q2_question",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "What can you infer from these results? Please consider the following plots, that display the distribution of the target variable in the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af211ff265ed59cbf36c7e1bc767ae0b",
     "grade": false,
     "grade_id": "q2_display2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "sns.countplot(y_train, ax=axes[0]);\n",
    "sns.countplot(y_test, ax=axes[1]);\n",
    "\n",
    "axes[0].set_title('Train')\n",
    "axes[1].set_title('Test')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30e3a02b026ba38a6e33871089722f0e",
     "grade": true,
     "grade_id": "q2_write",
     "locked": false,
     "points": 0,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Write your solution below:\n",
    "answers = \"\"\"\n",
    "In dataset, false target variable are more than true target variable. So our model tend to predict more false target in order to get more accuracy.\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c0c158bf2f2cfcf028c48008727be14",
     "grade": false,
     "grade_id": "q3_text",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "###  Question 3\n",
    "Now let's try to analyze the cross entropy loss. Recall that loss would be:\n",
    "$$\\Large L(\\theta) = -\\frac{1}{n} \\sum_{i=1}^n \\left( y_i \\phi(x_i)^T \\theta + \\log \\left(\\sigma\\left(-\\phi(x_i)^T \\theta\\right) \\right) \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f483ecd926ac3aa4f6e5a93415c6e33b",
     "grade": false,
     "grade_id": "q3_setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "theta = np.array([lr.coef_[0][0],\n",
    "                  lr.intercept_[0]])\n",
    "Phi = np.hstack([X,\n",
    "                 np.ones([len(X), 1])])\n",
    "print(theta)\n",
    "print()\n",
    "print(Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68f14212706044d49b51c17f8a2f1c6d",
     "grade": false,
     "grade_id": "q3_code",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def lr_loss(theta, Phi, Y):\n",
    "    '''\n",
    "    Compute the cross entropy loss using Phi, Y and theta. Hint: # The notation B @ v means: \n",
    "    compute the matrix multiplication Bv \n",
    "\n",
    "    Args:\n",
    "        theta: The model parameters. \n",
    "        Phi: The transformed input data \\phi(X)\n",
    "        Y: The label \n",
    "\n",
    "    Return:\n",
    "        The cross entropy loss.\n",
    "    '''\n",
    "    t = Phi @ theta\n",
    "    loss = - np.sum(Y * t - np.log(1 + np.exp(t)), axis=0) / Y.shape[0]\n",
    "\n",
    "#     YOUR CODE HERE\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ac1fca39089ffb61b85ac6424b306e5",
     "grade": true,
     "grade_id": "q3_test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(lr_loss(np.array([0,0]),\n",
    "                          Phi,\n",
    "                          Y),\n",
    "                  0.69314718055994529)\n",
    "assert np.isclose(lr_loss(theta,\n",
    "                          Phi,\n",
    "                          Y),\n",
    "                  0.34566168837055461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "317fc81199fbe2c3a93f99e00ebbec12",
     "grade": false,
     "grade_id": "q3_display",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "uvalues = np.linspace(-8,8,70)\n",
    "vvalues = np.linspace(-5,5,70)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "lr_loss_values = np.array([lr_loss(t, Phi, Y) for t in thetas.T])\n",
    "lr_loss_surface = go.Surface(name=\"Logistic Regression Loss\",\n",
    "        x=u, y=v, z=np.reshape(lr_loss_values,(len(uvalues), len(vvalues))),\n",
    "        contours=dict(z=dict(show=True, color=\"gray\", project=dict(z=True)))\n",
    "    )\n",
    "\n",
    "py.iplot(go.Figure(data=[lr_loss_surface]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8899542b628df7e740f585af83025e24",
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "What remarks can you make on this plot?\n",
    "Solution: One remark can be made is that this plot shows that there are multiple points that minimize the loss. Therefore, you cannot uniquely define the theta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "You're done!\n",
    "\n",
    "Before submitting this assignment, ensure to:\n",
    "\n",
    "1. Restart the Kernel (in the menubar, select Kernel->Restart & Run All)\n",
    "2. Validate the notebook by clicking the \"Validate\" button\n",
    "\n",
    "Finally, make sure to **submit** the assignment via the Assignments tab in Datahub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
