{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn in the homework, make sure everything runs as expected. To do so, select **Kernel**$\\rightarrow$**Restart & Run All** in the toolbar above.  Remember to submit both on **DataHub** and **Gradescope**.\n",
    "\n",
    "Please fill in your name and include a list of your collaborators below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Tianxiao Hu\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7901e087633730359931691b6fdc45c7",
     "grade": false,
     "grade_id": "cell-776bdcdaa31aa0dd",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Project 2: NYC Taxi Rides\n",
    "\n",
    "# Part 1: Data Wrangling\n",
    "In this notebook, we will first query a database to fetch our data and generate training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75116059d98993c05d7327802f166949",
     "grade": false,
     "grade_id": "cell-007c385238a61963",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "343c8b01b16a912914921eccfa8d1790",
     "grade": false,
     "grade_id": "cell-91e2a5cbad6e67c3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from utils import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62143d89efa5cc06cfba258687ef5e33",
     "grade": false,
     "grade_id": "cell-e456e639ff84ef40",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## SQLite\n",
    "[SQLite](https://www.sqlite.org/whentouse.html) is a SQL database engine that excels at managing data stored locally in a file. We will be using SQLite to query for our data. First let's check that our database is accessible and set up properly. Run the following line to make sure the data is there and pay attention to how big the data is. \n",
    "\n",
    "In practice, data is stored in a distributed SQL database that spans machines (e.g. [Hive](https://stackoverflow.com/questions/20030436/what-is-hive-is-it-a-database)) or even continents (e.g. [Spanner](https://en.wikipedia.org/wiki/Spanner_(database))). However, how you query the data will remain the same: the SQL language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef76e86a7f09c854a616aeb2e1189a88",
     "grade": false,
     "grade_id": "cell-c863071d3316689a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "!ls -lh /srv/db/taxi_2016_student_small.sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af295b132345635bf7901f358f70f751",
     "grade": false,
     "grade_id": "cell-0ae2136b7a30dc0f",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Running this line will connect to SQLite engine and test the connection by printing out the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c32085b9f669af381826fdf2def34d3a",
     "grade": false,
     "grade_id": "cell-1df5fd4847b76269",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "DB_URI = \"sqlite:////srv/db/taxi_2016_student_small.sqlite\"\n",
    "TABLE_NAME = \"taxi\"\n",
    "\n",
    "sql_engine = create_engine(DB_URI)\n",
    "with timeit():\n",
    "    print(f\"Table {TABLE_NAME} has {sql_engine.execute(f'SELECT COUNT(*) FROM {TABLE_NAME}').first()[0]} rows!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6ff0f03de3e0a7eefa4e4d2ae694913",
     "grade": false,
     "grade_id": "cell-f50d7e185525f6b6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Quick note: One piece of syntax above that you may not be familiar with is the Python [f-string](https://realpython.com/python-f-strings/), a relatively new feature to the language.\n",
    "\n",
    "Basically, it automatically replaces text inside curly braces with the results of the given expression. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c346c38cd64d0af600beadc4b11559f",
     "grade": false,
     "grade_id": "cell-a32bbd46f4d23829",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bloop = \"wet egg\"\n",
    "print(f\"{bloop} gets replaced, oh also {3 + 5}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9b685d4eea0e8a938c1ec33ecf4b06a",
     "grade": false,
     "grade_id": "cell-3c61687e3e98591b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# NYC Taxi Data\n",
    "\n",
    "We are working with a much larger dataset (15,000,000 rows!), larger than anything we have worked with before. If you are not careful in writing your queries, you may crash your kernel. Please do not `\"SELECT * FROM taxi\"`. This is a reality that we must face; we do not always get to work with supercomputers that can load everything in memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e2f4478d775511ecb225e1587445654",
     "grade": false,
     "grade_id": "cell-15edaada3d3db64b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Data Overview \n",
    "\n",
    "Below is the schema for the `taxi` database:\n",
    "```\n",
    "CREATE TABLE taxi_train(\n",
    "  \"record_id\" integer primary key,\n",
    "  \"VendorID\" INTEGER,\n",
    "  \"tpep_pickup_datetime\" TEXT,\n",
    "  \"tpep_dropoff_datetime\" TEXT,\n",
    "  \"passenger_count\" INTEGER,\n",
    "  \"trip_distance\" REAL,\n",
    "  \"pickup_longitude\" REAL,\n",
    "  \"pickup_latitude\" REAL,\n",
    "  \"RatecodeID\" INTEGER,\n",
    "  \"store_and_fwd_flag\" TEXT,\n",
    "  \"dropoff_longitude\" REAL,\n",
    "  \"dropoff_latitude\" REAL,\n",
    "  \"payment_type\" INTEGER,\n",
    "  \"fare_amount\" REAL,\n",
    "  \"extra\" REAL,\n",
    "  \"mta_tax\" REAL,\n",
    "  \"tip_amount\" REAL,\n",
    "  \"tolls_amount\" REAL,\n",
    "  \"improvement_surcharge\" REAL,\n",
    "  \"total_amount\" REAL\n",
    ");   \n",
    "```\n",
    "\n",
    "Here is a description for your convenience:\n",
    "- `recordID`: primary key of this dataset\n",
    "- `VendorID`: a code indicating the provider associated with the trip record\n",
    "- `passenger_count`: the number of passengers in the vehicle (driver entered value)\n",
    "- `trip_distance`: trip distance\n",
    "- `dropoff_datetime`: date and time when the meter was engaged\n",
    "- `pickup_datetime`: date and time when the meter was disengaged\n",
    "- `pickup_longitude`: the longitude where the meter was engaged\n",
    "- `pickup_latitude`: the latitude where the meter was engaged\n",
    "- `dropoff_longitude`: the longitude where the meter was disengaged\n",
    "- `dropoff_latitude`: the latitude where the meter was disengaged\n",
    "- `duration`: duration of the trip in seconds\n",
    "- `payment_type`: the payment type\n",
    "- `fare_amount`: the time-and-distance fare calculated by the meter\n",
    "- `extra`: miscellaneous extras and surcharges\n",
    "- `mta_tax`: MTA tax that is automatically triggered based on the metered rate in use\t\n",
    "- `tip_amount`: the\tamount of credit card tips, cash tips are not included\n",
    "- `tolls_amount`: amount paid for tolls\n",
    "- `improvement_surcharge`: fixed fee\n",
    "- `total_amount`: total amount paid by passengers, cash tips are not included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfbb90d949e41343e7470a885f7ba71b",
     "grade": false,
     "grade_id": "cell-7e63802ccfdd6050",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 1: SQL Warmup\n",
    "\n",
    "Let's begin with some SQL questions! Remember, be careful not to select too many entries in your query. Your kernel **will** crash! Please write your queries in the provided triple quotes and format them with proper SQL style. Below is an example which grabs the first 5 rows from the `taxi` database.\n",
    "\n",
    "We will use the `timeit` contextmanager from the `utils` file to time each SQL execution. *Beware that SQL can be slow sometimes; enterprise SQL quries often run for hours or days!* (several minutes execution time is [considered fast](https://hortonworks.com/blog/benchmarking-apache-hive-13-enterprise-hadoop/)). In each cell, we have added anitipated execution time to use as a guideline for writing your quries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cf6576ff212e546bbb471c196a23dbd",
     "grade": false,
     "grade_id": "cell-9462ab8556498136",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "q1x_query = f\"\"\"\n",
    "            SELECT * \n",
    "            FROM {TABLE_NAME}\n",
    "            LIMIT 5;\n",
    "            \"\"\"\n",
    "\n",
    "with timeit(): # this query should take less than a second\n",
    "    q1x_df = pd.read_sql(q1x_query, sql_engine)\n",
    "q1x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5038a8a9971a5a4ac9575a3e8d65fe91",
     "grade": false,
     "grade_id": "q1a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1a\n",
    "Select the top 1000 rows from the `taxi` database ordered by descending `total_amount`. Note that this data is real uncleaned data, with all the strange quirks that come from such datasets, e.g. you'll see that the most expensive taxi ride was $153,296.22, which is certainly some sort of error in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67733849cd0786fe5238dc6cb3e7d956",
     "grade": false,
     "grade_id": "q1a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q1a_query = \"\"\"\n",
    "            SELECT *\n",
    "            FROM taxi\n",
    "            ORDER BY total_amount DESC\n",
    "            LIMIT 1000\n",
    "            \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit(): # This query is expected to run for less than 20 seconds.\n",
    "    q1a_df = pd.read_sql(q1a_query, sql_engine)\n",
    "q1a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a75f0c1859dcfa9df1b15cce433f25d",
     "grade": true,
     "grade_id": "q1a-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(q1a_df) == 1000\n",
    "assert q1a_df.loc[0, 'total_amount'] >= q1a_df.loc[999, \"total_amount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17b11ad1fe742c7765b6695ef0db90bb",
     "grade": false,
     "grade_id": "q1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1b\n",
    "Get the `mean`, `max` and `min` `total_amount` for each vendor. As above, you'll get strange answers, since finding the min and max of a big uncleaned dataset captures the most extreme outliers. Make sure your query outputs the columns in this exact order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5cf5e9f2a92e447f90227c2ff53063e",
     "grade": false,
     "grade_id": "q1b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q1b_query = \"\"\"\n",
    "            SELECT AVG(total_amount) AS mean, MAX(total_amount) AS max, MIN(total_amount) AS min\n",
    "            FROM taxi\n",
    "            GROUP BY VendorID\n",
    "            \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit(): # This query is expected to run for about 10 seconds.\n",
    "    q1b_df = pd.read_sql_query(q1b_query, sql_engine)\n",
    "q1b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cf0712cc77f5e6042ebd8e0fa73df6d",
     "grade": true,
     "grade_id": "q1b-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert q1b_df.shape == (2, 3)\n",
    "assert 15 < q1b_df.iloc[0, 0] < 17\n",
    "assert q1b_df.iloc[1, 1] == 4887.30\n",
    "assert q1b_df.iloc[1, 2] == -958.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "feab5a35c19214c0b93bc74abb8d1837",
     "grade": false,
     "grade_id": "q1c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1c\n",
    "Find the total amount paid and pickup time for all rides that started June 28th, 2016, then order the result by total amount in descending order. Again, make sure your query outputs the columns in this exact order.\n",
    "\n",
    "*Hint:* From the schema, note that `tpep_pickup_datetime` is a text field. We're effectively looking for strings that have a start time that comes after `2016-06-28 00:00:00` but before `2016-06-29 00:00:00`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47862efc8f3ef66d67a5a2076a4ed3be",
     "grade": false,
     "grade_id": "q1c-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q1c_query = \"\"\"\n",
    "            SELECT total_amount, tpep_pickup_datetime\n",
    "            FROM taxi\n",
    "            WHERE tpep_pickup_datetime LIKE '2016-06-28%'\n",
    "            ORDER BY total_amount DESC\n",
    "            \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit(): # This query should take about 3 seconds.\n",
    "    q1c_df = pd.read_sql_query(q1c_query, sql_engine)\n",
    "q1c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce24d3d9a26efcfb22acf7c4114b9c2b",
     "grade": true,
     "grade_id": "q1c-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert q1c_df.iloc[0, 0] == 390.99\n",
    "assert q1c_df.shape == (74857, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f60863ded581b9a069b57bd1c27e8b5",
     "grade": false,
     "grade_id": "q1d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1d\n",
    "Find all rides starting in the month of January in the year 2016, selecting only those entries whose `record_id` ends in 00. \n",
    "\n",
    "Note: The rest of our questions in Part 1, Part 2 and Part 3 will be based off of the results of this query. In part 4, you will be to use anything else in the database for fitting a model (more later). Because of its importance for the rest of the assignment, your query must be correct for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb6ad85ec1dee7e837f74b68f65fdf38",
     "grade": false,
     "grade_id": "q1d-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q1d_query = \"\"\"\n",
    "            SELECT *\n",
    "            FROM taxi\n",
    "            WHERE tpep_pickup_datetime\n",
    "            BETWEEN '2016-01-01' AND '2016-02-01'\n",
    "            AND record_id % 100 == 0\n",
    "            ORDER BY tpep_pickup_datetime\n",
    "            \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit(): # This query should take less than 3 second\n",
    "    q1d_df = pd.read_sql_query(q1d_query, sql_engine)\n",
    "q1d_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d84c3a7731b1d732c25d6034068b17bc",
     "grade": true,
     "grade_id": "q1d-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert q1d_df.iloc[0].loc['tpep_pickup_datetime'] >= \"2016-01-01\"\n",
    "assert q1d_df.iloc[-1].loc['tpep_pickup_datetime'] <= \"2016-02-01\"\n",
    "assert q1d_df.shape == (23674, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baacd8ed199fc37e925cdfedcfa05917",
     "grade": false,
     "grade_id": "cell-2ed1465369900e6c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 2: Data Inspection\n",
    "\n",
    "We will refer to the table generated by Question 1d as `Jan16`. Note that we have not explicitly built a table called `Jan16` in our SQL database. We are instead using `Jan16` to represent the mathematical object that results from Question 1d. Let us now check some basic properties of `Jan16`. We will be addressing the following properties within our dataset:\n",
    "- missing data values\n",
    "- duplicated values\n",
    "- range of duration values\n",
    "- range of latitude and longitude values\n",
    "- range of passenger count values\n",
    "\n",
    "It is good practice to check these properties when presented with a new dataset. There are two ways to check these properties: Approach one is to write SQL queries that directly interact with the database. Approach two is to create a pandas dataframe and use pandas methods. Since you've already gotten similar practice with pandas earlier in the semester, we'll stick with approach one. \n",
    "\n",
    "In the following problems, you'll check these properties using SQL queries. We'll also provide you with the pandas solution so that you can compare with your SQL based solution. In order to be able to provide these pandas solutions, we need to store the result of your `q1d_query` into a dataframe, which we'll call `jan_16_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50bb1dfe7d1e0bab1c4d2850dcb913a7",
     "grade": false,
     "grade_id": "cell-bbc74e87d46766ae",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with timeit(): # less than 3 seconds\n",
    "    jan_16_df = pd.read_sql_query(q1d_query, sql_engine)\n",
    "jan_16_df['tpep_pickup_datetime'] = pd.to_datetime(jan_16_df['tpep_pickup_datetime'])\n",
    "jan_16_df['tpep_dropoff_datetime'] = pd.to_datetime(jan_16_df['tpep_dropoff_datetime'])\n",
    "jan_16_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6258b03c770302766bc999969df0c7bf",
     "grade": false,
     "grade_id": "cell-bbf693980f853c12",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "For the remaining questions in part 1, you'll be using nested queries. For example, the nested query below selects all rides with passenger count equal to 2 from `Jan16`. Reminder that Python automatically replaces the `\"q1d_query\"` in `temporary_table_query_example` with the contents of the string variable named `q1d_query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3ade99c90d9691fb62907d8b1be6a93",
     "grade": false,
     "grade_id": "cell-b0d30d16eb4609d3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Jan16 to dataframe using temporary table\n",
    "temporary_table_query_example = f\"\"\"\n",
    "SELECT *\n",
    "FROM ({q1d_query})\n",
    "WHERE passenger_count = 2;\"\"\"\n",
    "print(temporary_table_query_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fff86243efcc9e358fe3fd43fc9d0dab",
     "grade": false,
     "grade_id": "cell-037580655d4c124b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The cell below executes this nested query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe5175aa5e907268f9f6842acef181f3",
     "grade": false,
     "grade_id": "cell-51059f057b90abbe",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with timeit(): # less than 3 seconds\n",
    "    pd.read_sql_query(temporary_table_query_example, sql_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91a2d036166c15aa9ab683638bc31e08",
     "grade": false,
     "grade_id": "q2a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Question 2a\n",
    "\n",
    "Write a SQL query to check if `Jan16` contains any missing values. Unfortunately, in this table, missing values are *not* specified with NaN nor empty strings. For example, take a look at record ID 136700. What do you observe about the location information?  \n",
    "\n",
    "Write a SQL query `q2a_query` that collects all rows that have a missing `tpep_pickup_datetime`, `tpep_dropoff_datetime`, `pickup_longitude`, or `pickup_latitude`. Then set `number_of_rows_with_missing_values` to the number of rows that have at least one missing value.\n",
    "\n",
    "In pandas, we could use boolean indexing to filter out these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaeb35c1d96127afc02a12fde2b4352d",
     "grade": false,
     "grade_id": "cell-8685ab2a78e67042",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Inspecting record 136700 for your convience.\n",
    "\n",
    "pd.read_sql_query(f\"\"\"\n",
    "SELECT * \n",
    "FROM {TABLE_NAME} \n",
    "WHERE record_id = 136700\n",
    "\"\"\", sql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00e2a5ff1bd25381640d1886794dde04",
     "grade": false,
     "grade_id": "q2a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q2a_query = f\"\"\" \n",
    "            SELECT *\n",
    "            FROM ({q1d_query})\n",
    "            WHERE tpep_pickup_datetime = 0.0 \n",
    "                OR tpep_dropoff_datetime = 0.0 \n",
    "                OR pickup_longitude = 0.0 \n",
    "                OR pickup_latitude = 0.0;\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "with timeit(): # Should take < 3 seconds\n",
    "    q2a_df = pd.read_sql_query(q2a_query, sql_engine)\n",
    "q2a_df.head()\n",
    "number_of_rows_with_missing_values = q2a_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a49b08977239023fb2e928657426fec3",
     "grade": true,
     "grade_id": "q2a-test",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "937dbc7e4e902058d3ac52f483993f4c",
     "grade": false,
     "grade_id": "cell-7b72044e4245136f",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Write a SQL query `q2b_query` to help determine if there are any duplicate records in `Jan16`. Set the boolean `has_duplicates` variable to `True` or `False` based on what you learn. You may use `len(jan_16_df)` in your solution.\n",
    "\n",
    "For comparison, approach two (pandas) for duplicate checking looks like `num_duplicates = jan_16_df.duplicated(subset=jan_16_df.columns).sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31333d1da581f8d4758a0a1d445c0cb5",
     "grade": false,
     "grade_id": "q2b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q2b_query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ({q1d_query})\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "with timeit(): # should take < 3 seconds\n",
    "    q2b_df = pd.read_sql_query(q2b_query, sql_engine)\n",
    "q2b_df.head()\n",
    "\n",
    "has_duplicates = (not len(q2b_df) == len(jan_16_df)) # True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "103558de29ffc39eba712edd57ec6da3",
     "grade": true,
     "grade_id": "q2b-test",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a11fea32c57764a6dfcbecb6558b3611",
     "grade": false,
     "grade_id": "q2c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2c\n",
    "Find the min and max trip duration in `Jan16`. You may manually fill in the `min_duration`, `max_duration` placeholders.\n",
    "\n",
    "*Hint:* check [`julianday`](https://www.techonthenet.com/sqlite/functions/julianday.php) in `SQLite`. Your answer should be decimal representations of a day (e.g. 6 hours = 0.25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfd0c8fbfa06cd3ccc96c45868adf9cc",
     "grade": false,
     "grade_id": "q2c-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q2c_query = f\"\"\"\n",
    "            SELECT julianday(tpep_dropoff_datetime) - julianday(tpep_pickup_datetime)\n",
    "            FROM ({q1d_query})\n",
    "            ORDER BY julianday(tpep_dropoff_datetime) - julianday(tpep_pickup_datetime) DESC\n",
    "            \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit(): # should take < 3 seconds\n",
    "    q2c_df = pd.read_sql_query(q2c_query, sql_engine)\n",
    "q2c_df.head()\n",
    "\n",
    "min_duration = 0.0000\n",
    "max_duration = 0.999190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a873da9c2d74d7fe6d2217ccfcc85ab",
     "grade": true,
     "grade_id": "q2c-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_min_seconds = min(jan_16_df[\"tpep_dropoff_datetime\"] - jan_16_df[\"tpep_pickup_datetime\"]).total_seconds()\n",
    "df_max_seconds = max(jan_16_df[\"tpep_dropoff_datetime\"] - jan_16_df[\"tpep_pickup_datetime\"]).total_seconds()\n",
    "assert min_duration == df_min_seconds/86400\n",
    "assert np.isclose(max_duration,df_max_seconds/86400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d79a8437a9bc00123657f17f3790343",
     "grade": false,
     "grade_id": "cell-bef6581022a85dbf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "\n",
    "The cell above should have shown that some trips are extremely long (almost a day)! What is up with this? There may be several reasons why we have a handful of taxi rides with abnormally high durations. \n",
    "\n",
    "Using our domain knowledge about taxi businesses in NYC, we might believe that taxi drivers accidentally left their meters running, which causes high duration values to be recorded. This is a plausible explanation. Because of this, we will only train and predict on taxi ride data that has a duration of at most 12 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57cd0e08634e1a2c2bad250cc336bd55",
     "grade": false,
     "grade_id": "cell-108e691d490cfa1e",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 3: Data Cleaning\n",
    "Now let's use domain knowledge and clean up our data. You will use SQL while we perform the equivalent operations in pandas on `cleaned_jan_16_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b63686741aea4f297c1d6549365567ea",
     "grade": false,
     "grade_id": "cell-5dcc81cf856b1513",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cleaned_jan_16_df = jan_16_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2d670ae19a89bf9eb4630e52a340a90",
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3a\n",
    "Write a SQL Query to find all rides in `Jan16` that are less than 12 hours, or 0.5 days. We will use this query as a nested query `q3a_query` in question 3b.\n",
    "\n",
    "*Hint:* Ideas in `q1d_query` can be heavily reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "866b7fda2c015cedcb4a071619f0c4f1",
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q3a_query = f\"\"\"\n",
    "            SELECT *, julianday(tpep_dropoff_datetime) - julianday(tpep_pickup_datetime) AS tripduration\n",
    "            FROM ({q1d_query})\n",
    "            WHERE tripduration < 0.5\n",
    "            \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit(): # should take < 3 seconds\n",
    "    q3a_df = pd.read_sql_query(q3a_query, sql_engine)\n",
    "q3a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45d8f9c41807f0c630d4dfdad6a26f68",
     "grade": true,
     "grade_id": "q3a-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cleaned_jan_16_df['duration'] = cleaned_jan_16_df[\"tpep_dropoff_datetime\"]-cleaned_jan_16_df[\"tpep_pickup_datetime\"]\n",
    "cleaned_jan_16_df['duration'] = cleaned_jan_16_df['duration'].dt.total_seconds()\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['duration'] < 12 * 3600]\n",
    "assert len(q3a_df) == len(cleaned_jan_16_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be1b950116f92203bce8bcd69a91d211",
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3b\n",
    "\n",
    "Our objective is to predict the duration of taxi rides in the New York City region. Therefore, we should verify that our dataset contains only rides that are either starting or ending in New York (or are contained within the NY region). \n",
    "\n",
    "Based on different coordinate estimates of New York City, the (inclusive) latitude and longitude ranges are (roughly) as follows:\n",
    "\n",
    "- Latitude is between 40.63 and 40.85\n",
    "- Longitude is between -74.03 and -73.75\n",
    "\n",
    "Write a SQL query to find all rides in `q3a_query` that are within the New York City region. We will use this query as a temporary table `q3b_query` in question 3c.\n",
    "\n",
    "\n",
    "- Note: This query can be tedious to write. In practice people use special data types to encode geographical information. For example, if we were using Postgres (made in Berkeley!) instead of SQLite, we could use the geo-spatial data types provided as part of [PostGIS](https://postgis.net/). \n",
    "\n",
    "*Hint:* Ideas in `q3a_query` can be heavily reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "273d36a9697bf54a89396517df6dfce6",
     "grade": false,
     "grade_id": "q3b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Try using this function!\n",
    "def bounding_condition(lat_l, lat_u, lon_l, lon_u):\n",
    "    return f\"\"\"\n",
    "            pickup_longitude <= {lon_u} AND\n",
    "            pickup_longitude >= {lon_l} AND\n",
    "            dropoff_longitude <= {lon_u} AND\n",
    "            dropoff_longitude >= {lon_l} AND\n",
    "            pickup_latitude <= {lat_u} AND\n",
    "            pickup_latitude >= {lat_l} AND\n",
    "            dropoff_latitude <= {lat_u} AND\n",
    "            dropoff_latitude >= {lat_l} \n",
    "            \"\"\"\n",
    "\n",
    "lat_l = 40.63\n",
    "lat_u = 40.85\n",
    "lon_l = -74.03\n",
    "lon_u = -73.75\n",
    "\n",
    "q3b_query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ({q3a_query})\n",
    "            WHERE\n",
    "            \"\"\" + bounding_condition(lat_l, lat_u, lon_l, lon_u)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit(): # should take < 3 seconds\n",
    "    q3b_df = pd.read_sql_query(q3b_query, sql_engine)\n",
    "q3b_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a6f6427ae48628f91da3f0c5bdc19df",
     "grade": false,
     "grade_id": "cell-2e3c39b64b69b44b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "By contrast, the approach two (pandas) equivalent is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fefd29a93263c21960806676155fdd2",
     "grade": true,
     "grade_id": "q3b-test",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['pickup_longitude'] <= -73.75]\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['pickup_longitude'] >= -74.03]\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['pickup_latitude'] <= 40.85]\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['pickup_latitude'] >= 40.63]\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['dropoff_longitude'] <= -73.75]\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['dropoff_longitude'] >= -74.03]\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['dropoff_latitude'] <= 40.85]\n",
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['dropoff_latitude'] >= 40.63]\n",
    "assert len(q3b_df) == len(cleaned_jan_16_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "659b65ff7b17926579d79663e2fb31e3",
     "grade": false,
     "grade_id": "q3c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3c\n",
    "\n",
    "The `passenger_count` variable has a minimum value of 0 passengers and a maximum value of 9 passengers. Having 0 passengers does not make sense in the context of this business case; it is likely an error and should therefore be removed from our dataset.\n",
    "\n",
    "Write a SQL query to find all rides in `q3b_query` with `passenger_count` greater than 0.\n",
    "\n",
    "*Hint:* Ideas in `q3b_query` can be heavily reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9c50880c48df1b9c96223733e73017d",
     "grade": false,
     "grade_id": "q3c-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "q3c_query = f\"\"\"\n",
    "            SELECT *\n",
    "            FROM ({q3b_query})\n",
    "            WHERE passenger_count > 0\n",
    "            \"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with timeit():\n",
    "    q3c_df = pd.read_sql_query(q3c_query, sql_engine)\n",
    "q3c_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bc641eb805d8368edf92758504d6e54",
     "grade": true,
     "grade_id": "q3c-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cleaned_jan_16_df = cleaned_jan_16_df[cleaned_jan_16_df['passenger_count'] > 0]\n",
    "assert len(q3c_df) == len(cleaned_jan_16_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b7f07febdf95cde9514483b8e20c35e",
     "grade": false,
     "grade_id": "q3d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3d\n",
    "\n",
    "If you passed all the previous tests, then we are done cleaning! We would like to check how many records we have removed to ensure that it is a relatively small number (otherwise we might introduce bias within our dataset). In the cell below calculate the number and proportion of records we removed from the original `jan_16_df` during the data cleaning process. \n",
    "\n",
    "To avoid possible error propagation, you should use our `cleaned_jan_16_df` in your solution as the final cleaned dataset instead of your `q3c_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b439f2b2a29ea9360aa4646b5371e143",
     "grade": false,
     "grade_id": "q3d-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_records_removed = len(jan_16_df) - len(cleaned_jan_16_df)\n",
    "proportion_records_removed = num_records_removed / len(jan_16_df)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "print(f'Records removed:{num_records_removed}')\n",
    "print(f'Proportion records removed:{proportion_records_removed}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a6909fd66e6cac71c5bea5c827f52f0",
     "grade": true,
     "grade_id": "q3d-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert proportion_records_removed < 0.04\n",
    "assert proportion_records_removed > 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4342f4d9fe204397d3d7b57c997c9d50",
     "grade": false,
     "grade_id": "cell-d33807200b80aeef",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "At this point, let's take a look at the final query that cleaned up the data. Nesting SQL queries or creating views for future re-use are common pattern in analytical queries. Pay attention to each WHERE clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59401f3e7c47f398c65491329d80d760",
     "grade": false,
     "grade_id": "cell-58dc48871ccfe1d1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(q3c_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2e2071073867c793b809cd4b18c5112",
     "grade": false,
     "grade_id": "cell-6e3d69961fd26a76",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 4: Training and Validation Split\n",
    "Now that we have fetched and cleaned our data, let's create training and validation sets. We will use a 80/20 ratio for training/validation and set `random_state=42` for the purpose of grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d2ddbe31d71e1c1630ddda4e5cb66a6",
     "grade": false,
     "grade_id": "cell-da6cb006437c30d1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(cleaned_jan_16_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67d6847986360b44f9e1cc4a74af2288",
     "grade": false,
     "grade_id": "cell-79209a49cbca44b7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check that 80% records in training and 20% in validation set.\n",
    "assert len(train_df) < 18500\n",
    "assert len(train_df) > 17000\n",
    "assert len(val_df) > 4000\n",
    "assert len(val_df) < 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f656258232ef04f31c45a1dac7ca1f5",
     "grade": false,
     "grade_id": "cell-49aae7e52549bf99",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Part 1 Exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8dfcb121a890e0229c491f960cd71065",
     "grade": false,
     "grade_id": "cell-d80eaabbe34cc050",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Throughout our analysis, we have formatted and cleaned our data. Since we are ready to begin the feature engineering process, a good practice is to start a new notebook (since this one is getting quite long!). Now, we will save our formatted data, which we will load in part 2. **Be sure to run the cell below!**\n",
    "\n",
    "Please read the documentation below on saving and loading hdf files.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_hdf.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.read_hdf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b14b0de947a878d669e22b20e216c97",
     "grade": false,
     "grade_id": "cell-024027b771723779",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Path(\"data/part1\").mkdir(parents=True, exist_ok=True)\n",
    "data_file = Path(\"data/part1\", \"cleaned_data.hdf\") # Path of hdf file\n",
    "train_df.to_hdf(data_file, \"train\") # Train data of hdf file\n",
    "val_df.to_hdf(data_file, \"val\") # Val data of hdf file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4585f645e491f4686bc49e459dbee00",
     "grade": false,
     "grade_id": "cell-07eff5ec98e38de3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Part 1 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7495502082f47d72a3220956b488902",
     "grade": false,
     "grade_id": "cell-0fdea0303bcde612",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We have downloaded/loaded our data, cleaned the data, and split our data into a training and test set to use in future analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "516c7d8babe9cdf0082e463291a0bc6d",
     "grade": false,
     "grade_id": "cell-a6077a6f770d7237",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**Please proceed to part 2, where we will be exploring the taxi ride training set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!\n",
    "\n",
    "Before submitting this assignment, ensure that you have:\n",
    "\n",
    "1. Restarted the Kernel (in the menubar, select Kernel$\\rightarrow$Restart & Run All)\n",
    "2. Validated the notebook by clicking the \"Validate\" button.\n",
    "\n",
    "Then,\n",
    "\n",
    "1. **Submit** the assignment via the Assignments tab in **Datahub** \n",
    "1. **Upload and tag** the manually reviewed portions of the assignment on **Gradescope**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
