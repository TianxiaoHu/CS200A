{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn in the homework, make sure everything runs as expected. To do so, select **Kernel**$\\rightarrow$**Restart & Run All** in the toolbar above.  Remember to submit both on **DataHub** and **Gradescope**.\n",
    "\n",
    "Please fill in your name and include a list of your collaborators below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Tianxiao Hu\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: NYC Taxi Rides\n",
    "# Extras\n",
    "\n",
    "Put all of your extra work in here. Feel free to save figures to use when completing Part 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load the data. \n",
    "data_file = Path(\"./\", \"cleaned_data.hdf\")\n",
    "train_df = pd.read_hdf(data_file, \"train\")\n",
    "val_df = pd.read_hdf(data_file, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_df[\"duration\"].values)\n",
    "plt.title(\"duration before dropping outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[np.logical_and(train_df['duration'] < 4000, train_df['duration'] > 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_df[\"duration\"].values)\n",
    "plt.title(\"duration before dropping outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from part 2\n",
    "def haversine(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"\n",
    "    Compute haversine distance\n",
    "    \"\"\"\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    average_earth_radius = 6371\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * average_earth_radius * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "# Copied from part 2\n",
    "def manhattan_distance(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"\n",
    "    Compute Manhattan distance\n",
    "    \"\"\"\n",
    "    a = haversine(lat1, lng1, lat1, lng2)\n",
    "    b = haversine(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "# Copied from part 2\n",
    "def bearing(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"\n",
    "    Compute the bearing, or angle, from (lat1, lng1) to (lat2, lng2).\n",
    "    A bearing of 0 refers to a NORTH orientation.\n",
    "    \"\"\"\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "\n",
    "# Copied from part 2\n",
    "def add_time_columns(df):\n",
    "    \"\"\"\n",
    "    Add temporal features to df\n",
    "    \"\"\"\n",
    "    df.is_copy = False # propogate write to original dataframe\n",
    "    df.loc[:, 'month'] = df['tpep_pickup_datetime'].dt.month\n",
    "    df.loc[:, 'week_of_year'] = df['tpep_pickup_datetime'].dt.weekofyear\n",
    "    df.loc[:, 'day_of_month'] = df['tpep_pickup_datetime'].dt.day\n",
    "    df.loc[:, 'day_of_week'] = df['tpep_pickup_datetime'].dt.dayofweek\n",
    "    df.loc[:, 'hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "    df.loc[:, 'week_hour'] = df['tpep_pickup_datetime'].dt.weekday * 24 + df['hour']\n",
    "    return df\n",
    "\n",
    "# Copied from part 2\n",
    "def add_distance_columns(df):\n",
    "    \"\"\"\n",
    "    Add distance features to df\n",
    "    \"\"\"\n",
    "    df.is_copy = False # propogate write to original dataframe\n",
    "    df.loc[:, 'manhattan'] = manhattan_distance(lat1=df['pickup_latitude'],\n",
    "                                                lng1=df['pickup_longitude'],\n",
    "                                                lat2=df['dropoff_latitude'],\n",
    "                                                lng2=df['dropoff_longitude'])\n",
    "\n",
    "    df.loc[:, 'bearing'] = bearing(lat1=df['pickup_latitude'],\n",
    "                                   lng1=df['pickup_longitude'],\n",
    "                                   lat2=df['dropoff_latitude'],\n",
    "                                   lng2=df['dropoff_longitude'])\n",
    "    df.loc[:, 'haversine'] = haversine(lat1=df['pickup_latitude'],\n",
    "                                   lng1=df['pickup_longitude'],\n",
    "                                   lat2=df['dropoff_latitude'],\n",
    "                                   lng2=df['dropoff_longitude'])\n",
    "    return df\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    return data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blizzard(df):\n",
    "    df.is_copy = False\n",
    "    df = df[df[\"day_of_month\"] != 23]\n",
    "    return df\n",
    "\n",
    "def remove_negative(data, *columns):\n",
    "    data.is_copy = False\n",
    "    for column in columns:\n",
    "        median = np.median(data[column].values)\n",
    "        data[column] = np.where(data[column] < 0, median, data[column])\n",
    "    return data\n",
    "\n",
    "def replace_zero(data, *columns):\n",
    "    data.is_copy = False\n",
    "    for column in columns:\n",
    "        median = np.median(data[column].values)\n",
    "        data[column] = np.where(data[column] == 0, median, data[column])\n",
    "    return data\n",
    "\n",
    "def replace_outlier(data, *columns):\n",
    "    data.is_copy = False\n",
    "    \n",
    "    def calculate_outlier_bound(arr):\n",
    "        q3 = np.percentile(arr, 75)\n",
    "        q1 = np.percentile(arr, 25)\n",
    "        iqr = q3 - q1\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        return [lower, upper]\n",
    "    \n",
    "    for column in columns:\n",
    "        lower, upper = calculate_outlier_bound(data[column].values)\n",
    "        median = np.median(data[column].values)\n",
    "        data[column] = np.where(np.logical_or(data[column].values < lower, data[column].values > upper), median, data[column])\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, test=False):\n",
    "    data_clean = (  data\n",
    "                    .pipe(add_time_columns)\n",
    "                    .pipe(remove_blizzard)\n",
    "                    .pipe(add_distance_columns)\n",
    "                    .pipe(remove_negative, \n",
    "                          'extra', \n",
    "                          'mta_tax', \n",
    "                          'improvement_surcharge',\n",
    "                          'fare_amount', \n",
    "                          'total_amount')\n",
    "                    .pipe(replace_zero,\n",
    "                          'pickup_longitude',\n",
    "                          'pickup_latitude',\n",
    "                          'dropoff_longitude',\n",
    "                          'dropoff_latitude')\n",
    "                    .pipe(replace_outlier,        \n",
    "                          'fare_amount', \n",
    "                          'total_amount',\n",
    "                          'duration')\n",
    "    )\n",
    "    X = data_clean.pipe(select_columns, \n",
    "                      'passenger_count', \n",
    "                      'trip_distance', \n",
    "                      'pickup_longitude', \n",
    "                      'pickup_latitude', \n",
    "                      'dropoff_longitude', \n",
    "                      'dropoff_latitude', \n",
    "                      'day_of_month', \n",
    "                      'fare_amount', \n",
    "                      'extra', \n",
    "                      'mta_tax', \n",
    "                      'tip_amount',\n",
    "                      'tolls_amount', \n",
    "                      'improvement_surcharge', \n",
    "                      'total_amount',\n",
    "                      'day_of_week', \n",
    "                      'hour', \n",
    "                      'week_hour', \n",
    "                      'manhattan', \n",
    "                      'bearing', \n",
    "                      'haversine',\n",
    "                      'duration')\n",
    "    \n",
    "    if test:\n",
    "        y = None\n",
    "    else:\n",
    "        y = X['duration']\n",
    "        \n",
    "    X = X.drop('duration', axis=1)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(train_df)\n",
    "X_val, y_val = process_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Ridge regression\n",
    "model = Ridge()\n",
    "\n",
    "alpha = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300]\n",
    "optimized_model = GridSearchCV(model, param_grid={'alpha': alpha}, cv=5)\n",
    "optimized_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Paramaters:\")\n",
    "print(optimized_model.best_params_)\n",
    "print(\"Grid Scores:\")\n",
    "means = optimized_model.cv_results_['mean_test_score']\n",
    "stds = optimized_model.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, optimized_model.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "\n",
    "y_train_pred = optimized_model.predict(X_train)\n",
    "print(\"MAE for Train Data:\")\n",
    "print(mean_absolute_error(y_train, y_train_pred))\n",
    "y_val_pred = optimized_model.predict(X_val)\n",
    "print(\"MAE for Val Data:\")\n",
    "print(mean_absolute_error(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300]\n",
    "train_mae = []\n",
    "val_mae = []\n",
    "for para in alpha:\n",
    "    model = Lasso(alpha=para)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_mae.append(mean_absolute_error(y_train, model.predict(X_train)))\n",
    "    val_mae.append(mean_absolute_error(y_val, model.predict(X_val)))\n",
    "    \n",
    "plt.plot(range(len(train_mae)),train_mae)\n",
    "plt.plot(range(len(val_mae)),val_mae)\n",
    "plt.xticks(range(1, len(train_mae)+1), alpha)\n",
    "plt.title(\"MAE vs alpha\")\n",
    "plt.legend(\"train\", \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!\n",
    "\n",
    "Before submitting this assignment, ensure that you have:\n",
    "\n",
    "1. Restarted the Kernel (in the menubar, select Kernel$\\rightarrow$Restart & Run All)\n",
    "2. Validated the notebook by clicking the \"Validate\" button.\n",
    "\n",
    "Then,\n",
    "\n",
    "1. **Submit** the assignment via the Assignments tab in **Datahub** \n",
    "1. **Upload and tag** the manually reviewed portions of the assignment on **Gradescope**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
